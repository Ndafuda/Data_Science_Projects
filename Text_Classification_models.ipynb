{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08f5fb2e",
   "metadata": {},
   "source": [
    "## Text Classification Model on Song Lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c811698",
   "metadata": {},
   "source": [
    "### Project Goals: \n",
    "    Extracting lyrics dataset and build a classification model which could predict an artist from a piece of text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9e4c9198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8d444f",
   "metadata": {},
   "source": [
    "### Songs ULRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f2ebc212",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_fassie = 'https://www.lyrics.com/artist/Brenda-Fassie/21870'\n",
    "url_carey = 'https://www.lyrics.com/artist/Mariah-Carey/62404'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7cc4bd",
   "metadata": {},
   "source": [
    "### Convert html to text and to bs object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e83bdd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    r = requests.get(url)\n",
    "    text = r.text\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d9f8223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_fassie = get_soup(url_fassie)\n",
    "soup_carey = get_soup(url_carey)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019bf994",
   "metadata": {},
   "source": [
    "### Requesting and getting the list of lyrics links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3a641df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lyrics_links(soup):\n",
    "    '''Returns the list of lyric links.'''\n",
    "    list_of_links = []\n",
    "    for a in soup.find_all('a', href = True):\n",
    "        href = a['href']\n",
    "        if '/lyric/'in href:\n",
    "            list_of_links.append('https://www.lyrics.com'+href)\n",
    "    return list_of_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c8ec3d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "fassie_list_of_links = get_lyrics_links(soup_fassie)\n",
    "carey_list_of_links = get_lyrics_links(soup_carey)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf52fcd0",
   "metadata": {},
   "source": [
    "### Downloading and saving the song lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a71d9446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path(links):\n",
    "    for link in links:\n",
    "        artist = re.sub(\"\\+\", \"_\", link.split(\"/\")[-2])\n",
    "        directory = f\"../data/{artist}/\"\n",
    "    return directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ef5f16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "def downloading_and_saving_lyrics(links):\n",
    "    '''a function that request, download and save song lyrics.'''\n",
    "    for link in tqdm(links):\n",
    "        artist = re.sub(\"\\+\", \"_\", link.split(\"/\")[-2])\n",
    "        song = link.split(\"/\")[-1]\n",
    "        songname =  f\"{directory}/\"+re.sub(\"\\+\", \"_\", f\"{song}.txt\")\n",
    "        r_soup = BeautifulSoup(requests.get(link).text, \"html.parser\")\n",
    "        try:\n",
    "            lyric1 = r_soup.find(\"pre\", {\"id\":\"lyric-body-text\"}).text\n",
    "            with open(songname, \"w\") as file:\n",
    "                file.write(lyric1)\n",
    "        except AttributeError: \n",
    "            print(link)\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e158ecd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1/1 [00:06<00:00,  6.12s/it]\n"
     ]
    }
   ],
   "source": [
    "downloading_and_saving_lyrics(carey_list_of_links[8:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cfafda",
   "metadata": {},
   "source": [
    "### Creating a corpus / bag of Words with song lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "97c3f096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "corpus_list = []\n",
    "def make_corpus_list(folder):\n",
    "    '''a function that create opens saved song lyrics (from their respective folders),\n",
    "    and adding them to a list (or 2 lists?).'''\n",
    "    for lyric in os.listdir(f\"{directory}/\"):\n",
    "         corpus = open(f\"{directory}/\" + lyric).read()\n",
    "         corpus_list.append(corpus)\n",
    "    return corpus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5743e182",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = get_path(carey_list_of_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "29a6d766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "fassie_corpus_list = []\n",
    "carey_corpus_list = []\n",
    "\n",
    "for fn in os.listdir('../data/Brenda_Fassie/'):\n",
    "     corpus_fassie = open('../data/Brenda_Fassie/' + fn).read()\n",
    "     fassie_corpus_list.append(corpus_fassie)\n",
    "    \n",
    "for fn in os.listdir('../data/Mariah_Carey/'):\n",
    "     corpus_carey = open('../data/Mariah_Carey/' + fn).read()\n",
    "     carey_corpus_list.append(corpus_carey)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e4f228e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_list = fassie_corpus_list + carey_corpus_list\n",
    "labels = [\"fassie\"]*17 + [\"carey\"]*17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070380ff",
   "metadata": {},
   "source": [
    "### Transforming the corpus/words into a matrix using count Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3e7faef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a23eff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', max_df=0.8)\n",
    "vectorizer.fit(corpus_list)\n",
    "X= vectorizer.transform(corpus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "133a0231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<34x883 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1434 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4871e6",
   "metadata": {},
   "source": [
    "X_df = pd.DataFrame(X.todense(), columns=vectorizer.get_feature_names(), index=labels)\n",
    "X_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929b55ee",
   "metadata": {},
   "source": [
    "### Normalises the word counts using TF_IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d9cd4b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf = TfidfTransformer() \n",
    "X_norm = tf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "096cd29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm_df=pd.DataFrame(X_norm.todense(), columns=vectorizer.get_feature_names_out(), index=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ed1273",
   "metadata": {},
   "source": [
    "### Classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2349a2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c9092947",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X_norm_df\n",
    "y=labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24e7979",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ea39675e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5555555555555556, 1.0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_m = LogisticRegression()\n",
    "l_m.fit(X_train, y_train)\n",
    "l_m.score(X_test, y_test),l_m.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7ad91080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['carey', 'carey', 'carey', 'fassie', 'fassie', 'fassie', 'carey',\n",
       "       'fassie', 'carey', 'fassie', 'fassie', 'carey', 'carey', 'carey',\n",
       "       'fassie', 'fassie', 'carey', 'carey', 'carey', 'fassie', 'fassie',\n",
       "       'carey', 'carey', 'fassie', 'fassie'], dtype='<U6')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_m.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2837ea0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<34x883 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1434 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df7b2ff",
   "metadata": {},
   "source": [
    "#### Naive Bayes in sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c70c1212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nm_m = MultinomialNB()\n",
    "nm_m.fit(X, y)\n",
    "nm_m.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d9f20a",
   "metadata": {},
   "source": [
    "#### Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6e20b46b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=4, n_estimators=20, random_state=10)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# n_est should go up, max_depth can go down\n",
    "rf = RandomForestClassifier(n_estimators=20, \n",
    "                            max_depth=4, \n",
    "                            random_state=10)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "63e7104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d82ee851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.7777777777777778)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_train, y_train), rf.score(X_test, y_test),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3e7dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
